{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pylab as plt\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracción, transformación y limpieza de datos del dataset de películas, series y documentales de Netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = pd.read_csv('../data/Net_titles.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "actor = pd.read_csv('../data/Net_credits.csv', encoding='utf-8', encoding_errors='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para rellenar los valores nulos de la columna Age_certification. Si pertenece a los siguientes géneros se asumirá que la certificación de edad es R (+17)\n",
    "def fill_age_null(row):\n",
    "    if pd.isna(row['age_certification']):\n",
    "        if 'thriller' in row['genres'] or 'horror' in row['genres'] or 'black comedy' in row['genres']:\n",
    "            return 'R'\n",
    "    return row['age_certification']\n",
    "\n",
    "film['age_certification'] = film.apply(lambda row: fill_age_null(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los valores nulos de las columnas relacionados con IMDB y TMDB, ya que sin el imdb_id es imposible analizarlos\n",
    "# Rellenamos los valores nulos de la columna seasons con '-1'\n",
    "# Rellenamos los valores nulos de la columna character del df 'actor' con la palabra 'unknown'\n",
    "# Rellenamos los valores nulos de la columna description con 'unknown'\n",
    "# Rellenamos los valores nulos de la columna age_certification con 'unknown'\n",
    "\n",
    "film.dropna(subset=['imdb_id', 'imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score'], inplace=True)\n",
    "film['age_certification'] = film['age_certification'].fillna('unknown')\n",
    "film['seasons'] = film['seasons'].fillna('-1')\n",
    "film['description'] = film['description'].fillna('unknown')\n",
    "actor['character'] = actor['character'].fillna('unknown')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5131/5131 [14:34<00:00,  5.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_reviews_and_ratings(imdb_id):\n",
    "    url = f'https://www.imdb.com/title/{imdb_id}/reviews?ref_=tt_ov_rt' \n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        reviews = soup.find_all('div', {'class': 'text show-more__control'})  \n",
    "        ratings = soup.find_all('span', {'class': 'rating-other-user-rating'})\n",
    "        results = []                                        # crea la lista para almacenar los resultados\n",
    "        for rev, rat in zip(reviews, ratings):              # itera sobre reviews y rating a la vez\n",
    "            rev_div = rev.find_parent('div', {'class': 'lister-item-content'})  \n",
    "            rev_title = rev_div.find('a', {'class': 'title'}).text.strip() if rev_div.find('a', {'class': 'title'}) else 'No title'\n",
    "            rat_title = rat.text.strip() if rat else 'Sin calificación'\n",
    "            results.append((imdb_id, rev_title, rat_title))\n",
    "        return results\n",
    "    else:\n",
    "        print(f'Error al obtener comentarios de la película con IMDB ID {imdb_id}')\n",
    "        return []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    imdb_ids = film['imdb_id'].tolist()                                                                                         #pasamos la columna del df a lista\n",
    "    reviews_and_ratings = Parallel(n_jobs=-1)(delayed(extract_reviews_and_ratings)(imdb_id) for imdb_id in tqdm(imdb_ids))      #extraemos en paralelo las reviews y ratings de cada id\n",
    "    reviews_and_ratings = [review for sublist in reviews_and_ratings for review in sublist]                                     #aplanamos la lista de listas 'reviews_and_ratings'\n",
    "    com_rev = pd.DataFrame(reviews_and_ratings, columns=['id', 'review_title', 'rating_title'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#com_rev.to_csv('../data/Net_comments.csv', index=False)\n",
    "#film.to_csv('../data/Net_titles_clean.csv', index=False)\n",
    "#actor.to_csv('../data/Net_actors_clean.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el mismo proceso con las tablas de HBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = pd.read_csv('../data/HBO_titles.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "actor = pd.read_csv('../data/HBO_credits.csv', encoding='utf-8', encoding_errors='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_age_null(row):\n",
    "    if pd.isna(row['age_certification']):\n",
    "        if 'thriller' in row['genres'] or 'horror' in row['genres'] or 'black comedy' in row['genres']:\n",
    "            return 'R'\n",
    "    return row['age_certification']\n",
    "\n",
    "film['age_certification'] = film.apply(lambda row: fill_age_null(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "film.dropna(subset=['imdb_id', 'imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score'], inplace=True)\n",
    "film['age_certification'] = film['age_certification'].fillna('unknown')\n",
    "film['seasons'] = film['seasons'].fillna('-1')\n",
    "film['description'] = film['description'].fillna('unknown')\n",
    "actor['character'] = actor['character'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2606/2606 [12:14<00:00,  3.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_reviews_and_ratings(imdb_id):\n",
    "    url = f'https://www.imdb.com/title/{imdb_id}/reviews?ref_=tt_ov_rt' \n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        reviews = soup.find_all('div', {'class': 'text show-more__control'})  \n",
    "        ratings = soup.find_all('span', {'class': 'rating-other-user-rating'})\n",
    "        results = []\n",
    "        for rev, rat in zip(reviews, ratings):\n",
    "            rev_div = rev.find_parent('div', {'class': 'lister-item-content'})  \n",
    "            rev_title = rev_div.find('a', {'class': 'title'}).text.strip() if rev_div.find('a', {'class': 'title'}) else 'No title'\n",
    "            rat_title = rat.text.strip() if rat else 'Sin calificación'\n",
    "            results.append((imdb_id, rev_title, rat_title))\n",
    "        return results\n",
    "    else:\n",
    "        print(f'Error al obtener comentarios de la película con IMDB ID {imdb_id}')\n",
    "        return []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    imdb_ids = film['imdb_id'].tolist()\n",
    "    reviews_and_ratings = Parallel(n_jobs=-1)(delayed(extract_reviews_and_ratings)(imdb_id) for imdb_id in tqdm(imdb_ids))\n",
    "    reviews_and_ratings = [review for sublist in reviews_and_ratings for review in sublist]\n",
    "    com_rev = pd.DataFrame(reviews_and_ratings, columns=['id', 'review_title', 'rating_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#com_rev.to_csv('../data/HBO_comments.csv', index=False)\n",
    "#film.to_csv('../data/HBO_titles_clean.csv', index=False)\n",
    "#actor.to_csv('../data/HBO_actors_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ETL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
